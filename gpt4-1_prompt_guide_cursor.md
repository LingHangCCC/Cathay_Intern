- GPT-4.1 來了！但你知道怎麼跟它「好好說話」嗎？
- 讓 GPT-4.1 變身超級助理：Agentic Workflows 指南
- 處理海量資訊？GPT-4.1 的長文本超能力
- 引導 GPT-4.1「想清楚再說」：思維鏈 (Chain of Thought) 的妙用
- 指哪打哪！GPT-4.1 的超強指令遵循能力
- 終極提示詞結構與分隔符建議
- 結語：釋放 GPT-4.1 的全部力量

# 精通 GPT-4.1 提示詞：釋放下一代 AI 潛能的實戰指南

> 探索 OpenAI 最新的 GPT-4.1 模型，學習如何透過優化提示詞 (Prompt) 來駕馭其強大的程式編寫、指令遵循和長文本處理能力。本指南將分享實用的技巧和範例，助您充分發揮 GPT-4.1 的潛力。

此文章為官方釋出 GPT-4.1 Prompting Guide 簡化版，若需要完整文章請閱讀此。

## GPT-4.1 來了！但你知道怎麼跟它「好好說話」嗎？

嘿，各位 AI 玩家和開發者們！OpenAI 又放大招了，推出了 GPT-4.1 系列模型。跟之前的 GPT-4o 相比，它在寫程式碼、理解指令，還有處理超長文件方面，簡直是跳了一大級。是不是很興奮？

不過，俗話說得好，「工欲善其事，必先利其器」。要讓這位新來的「高手」發揮十成功力，得學會怎麼跟它溝通，也就是所謂的「提示詞工程」(Prompt Engineering)。

這篇文章就是你的武功秘笈！整理了大量內部測試的心得，就是要幫你掌握駕馭 GPT-4.1 的訣竅。

等等，舊的提示詞技巧還管用嗎？

很多老方法依然有效，像是給它一些範例參考（Context Examples）、指令越清楚具體越好、引導它先「思考規劃」再行動等等。這些都能讓模型變得更聰明。

但！請注意，GPT-4.1 有個重要的轉變：它比前輩們 更「聽話」 ，會更嚴格、更照字面意思來遵循你的指令。以前的模型可能比較會「猜」你想幹嘛，但 GPT-4.1 就比較一板一眼。

這有好有壞。好處是，只要你的指令夠明確，它就能被精準地引導；壞處是，如果你期望它像以前一樣「心領神會」，那結果可能會出乎意料。不過別擔心，通常只要補上一句堅定且毫不含糊的指令，就能把它導回正軌。

接下來，會分享一些實用的提示詞範例，但請記得，AI 工程是門實驗科學，沒有萬能丹。最重要的還是要多方嘗試、建立有效的評估機制，並持續迭代，才能找到最適合你應用場景的方法。

準備好了嗎？讓開始探索 GPT-4.1 的提示詞魔法吧！

## 讓 GPT-4.1 變身超級助理：Agentic Workflows 指南

你知道嗎？GPT-4.1 非常適合用來打造所謂的「代理式工作流程」(Agentic Workflows)。簡單來說，就是讓 AI 不只回答單一問題，而是能自主執行一系列步驟來完成更複雜的任務，就像一個小助理一樣。

在訓練 GPT-4.1 時，特別強化了它解決問題的「代理」能力。事實上，在針對軟體工程任務的 SWE-bench 測試中，的代理式設定解決了高達 55% 的問題，這在非推理模型中可是頂尖水準！

打造得力助手的三個「咒語」

為了讓 GPT-4.1 的代理能力全開，強烈建議在所有「代理提示詞」中加入以下三種關鍵提醒。雖然下面的範例是針對寫程式碼的場景優化，但稍作修改就能應用於其他代理任務：

1. 堅持到底 (Persistence)： 告訴模型這是一個需要多輪對話的任務，別中途「放棄治療」把控制權交還給你。 範例：「你是一位代理程式 - 請持續執行，直到使用者的請求完全解決為止，才能結束你的回合並將控制權交還。只有當你確定問題已解決時，才能終止你的回合。」 白話說：就是讓它知道「這事兒沒完，繼續做！」
1. 善用工具 (Tool-calling)： 鼓勵模型充分利用你提供給它的工具（例如讀取檔案、執行程式碼等），而不是自己瞎猜或幻想答案。 範例：「如果你不確定與使用者請求相關的檔案內容或程式碼結構，請使用你的工具讀取檔案並收集相關資訊：不要猜測或編造答案。」 白話說：「不懂就查，別自己亂掰！」
1. 先想後做 (Planning) [可選]： 如果你希望模型在每次使用工具前都先思考並說明計劃，而不是默默地連續呼叫工具，可以加上這個。 範例：「你必須在每次呼叫函式前進行詳盡的規劃，並在每次函式呼叫後深入反思其結果。不要僅僅透過呼叫函式來完成整個過程，這可能會影響你解決問題和深入思考的能力。」 白話說：「動手前先想想，告訴我你要幹嘛，做完後再想想結果。」

效果驚人！

說出來你可能不信，單單加上這三條簡單的指令，內部在 SWE-bench 測試上的分數就提高了將近 20%！這讓模型從一個比較被動的聊天機器人，轉變成一個更「積極」、能自主推動任務的代理。所以，強烈建議大家從這三點開始打造你的代理提示詞。

關於「工具呼叫」的小提醒

跟以前的模型比，GPT-4.1 在使用 API 中 tools 欄位傳遞的工具方面，受過更多訓練。鼓勵開發者 只用 這個 tools 欄位來提供工具，而不是像以前有些人會把工具描述手動塞進提示詞裡，然後再自己寫解析器。

為什麼？因為使用標準的 tools 欄位是減少錯誤、確保模型在執行工具呼叫時表現穩定的最佳方式。的實驗也證明，使用 API 解析的工具描述，比起手動注入到系統提示詞中，SWE-bench 的通過率提高了 2%。

給工具取個好名字，並在 description 欄位提供清晰、詳細的描述。同樣地，工具的每個參數也要有好名字和好描述。如果你的工具特別複雜，想提供使用範例，建議在系統提示詞裡開一個 # Examples 區塊放範例，而不是塞在 description 裡。範例可以幫助模型了解何時該用工具、是否要連同使用者文字一起呼叫、以及針對不同輸入該用哪些參數。

讓模型「大聲思考」：誘導式規劃與思維鏈

前面提到，你可以選擇性地讓 GPT-4.1 代理在工具呼叫之間進行規劃和反思。雖然 GPT-4.1 本身不是「推理模型」（它不會在回答前產生內部的思考鏈），但你可以透過類似上面「Planning」的提示詞，誘導它在輸出中明確地一步步展示其思考過程，就像「大聲思考」一樣。

在的 SWE-bench 代理任務實驗中，誘導明確的規劃讓通過率提升了 4%。這在處理複雜問題時特別有用，能讓你更清楚模型是怎麼「想」的。

## 處理海量資訊？GPT-4.1 的長文本超能力

GPT-4.1 的另一個亮點是它強大的長文本處理能力，輸入窗口高達 100 萬個 token！這代表什麼？你可以把超長的文件、大量的程式碼、或者一整本書的內容丟給它，讓它幫你：

- 解析結構化文件
- 重新排序資訊
- 從大量內容中挑選相關資訊（並忽略不相關的）
- 進行需要跨多個段落或文件的多步推理

長文本雖好，但也要注意

雖然 GPT-4.1 在「大海撈針」的測試中表現優異（即使在 100 萬 token 的極限下），處理混合了相關和不相關資訊的複雜任務也很在行，但有幾點要注意：

- 資訊越多越難找： 當需要模型從極長文本中檢索的項目越多時，效能可能會下降。
- 全局推理的挑戰： 對於需要理解整個文本狀態才能完成的複雜推理（例如圖搜索），長文本的挑戰更大。

調整模型對「外部知識」的依賴

有時候，你希望模型嚴格只根據你提供的文本來回答，避免它「自由發揮」；有時候，你又希望它能結合自身的知識來補充或連結資訊。你可以透過指令來調整：

- 嚴格模式（只用提供內容）：

```plaintext
    # Instructions
    // for internal knowledge
    - 只能使用提供的外部內容 (External Context) 來回答使用者查詢。如果你根據此內容不知道答案，即使使用者堅持要你回答，你也必須回應「我沒有回答所需的資訊」。
```

- 彈性模式（結合自身知識）：

```plaintext
    # Instructions
    // For internal and external knowledge
    - 預設使用提供的外部內容來回答使用者查詢，但如果回答需要其他基本知識，且你對答案有信心，你可以使用一些自己的知識來協助回答。
```

提示詞的「擺放藝術」

尤其在處理長文本時，指令和內容的擺放位置會影響效果。的經驗是：

- 最佳策略（三明治法）： 把你的主要指令放在 提供的長文本內容之前和之後各放一次 。
- 次佳策略（指令優先）： 如果你只想放一次指令，放在 內容之前 比放在之後效果更好。

記住這個小技巧，能幫助模型更好地抓住重點！

## 引導 GPT-4.1「想清楚再說」：思維鏈 (Chain of Thought) 的妙用

前面提過，GPT-4.1 不是天生的「推理模型」，但可以透過提示詞引導它進行「思維鏈」(Chain of Thought, CoT)，也就是讓它在回答前先一步步把問題拆解、思考、分析。

這有什麼好處？能顯著提升輸出的品質和準確性，尤其對複雜問題。代價是會消耗更多輸出 token，成本和延遲會高一些。好消息是，GPT-4.1 本身在代理推理和解決實際問題方面訓練得不錯，通常不需要太費力的提示就能做得很好。

基礎 CoT 指令：

可以在提示詞的末尾加上這句簡單的指令作為起點：

```plaintext
...
首先，仔細逐步思考需要哪些文件來回答查詢。然後，打印出每個文件的標題 (TITLE) 和 ID。接著，將這些 ID 格式化成一個列表。
```

進階 CoT 策略：

如果基礎版效果不彰，你可以觀察模型在你的特定範例或評估中是怎麼「想錯」的，然後用更明確的指令來修正它的規劃或推理錯誤。例如，如果發現模型容易誤解使用者意圖，或沒有充分分析上下文，可以加入更詳細的推理策略：

```plaintext
# Reasoning Strategy
1. 查詢分析 (Query Analysis): 分解並分析查詢，直到你確信理解其意圖。利用提供的上下文來釐清任何模糊或令人困惑的資訊。
2. 上下文分析 (Context Analysis): 仔細選擇並分析一大組可能相關的文件。優先考慮召回率 (recall) - 有些不相關也沒關係，但正確的文件必須在這個清單中，否則最終答案會是錯的。每個文件的分析步驟：
    a. 分析 (Analysis): 分析該文件與回答查詢的相關性（或不相關性）。
    b. 相關性評分 (Relevance rating): [高, 中, 低, 無]
3. 綜合 (Synthesis): 總結哪些文件最相關及其原因，包含所有相關性評分為中或更高的文件。

# User Question
{user_question}

# External Context
{external_context}

首先，仔細逐步思考需要哪些文件來回答查詢，嚴格遵守提供的推理策略 (Reasoning Strategy)。然後，打印出每個文件的標題 (TITLE) 和 ID。接著，將這些 ID 格式化成一個列表。
```

關鍵在於觀察、迭代，找出最適合你需求的 CoT 提示方式。

## 指哪打哪！GPT-4.1 的超強指令遵循能力

GPT-4.1 最令人印象深刻的特點之一，就是它出色的「指令遵循」能力。這意味著開發者可以非常精確地塑造和控制模型的輸出，滿足各種特定需求，像是：

- 代理推理步驟
- 回應的語氣和風格
- 工具呼叫的時機和資訊
- 輸出的格式
- 需要避開的話題等等

但正如前面提到的，它的「字面化」意味著你需要更明確地指示它「該做什麼」和「不該做什麼」。如果你把之前為其他模型優化的提示詞直接搬過來，可能會發現效果不如預期，因為 GPT-4.1 會更嚴格地遵循現有指令，而不太會去推斷那些「潛規則」。

指令開發與除錯流程建議：

1. 從大方向開始： 建立一個整體的「回應規則」(Response Rules) 或「指令」(Instructions) 區塊，用條列式說明高層次的指導原則。
1. 針對性調整： 如果想改變某個特定行為，可以增加更詳細的分類區塊，例如 # Sample Phrases （範例語句）。
1. 明確步驟： 如果希望模型遵循特定的工作流程，使用有序列表（1, 2, 3…）並指示模型遵循這些步驟。
1. 疑難排解： 如果行為仍然不符合預期： 檢查衝突或模糊指令： 確保沒有互相矛盾、不夠具體或錯誤的指令/範例。如果指令衝突，GPT-4.1 傾向於遵循 靠近提示詞末尾 的那個。 加入範例： 提供清晰展示期望行為的範例。確保範例中體現的重要行為也在規則中有文字說明。 少用「激勵」手段： 通常不需要使用全大寫、給小費或威脅利誘等方式。先試試不用這些，如果真的對你的特定場景有幫助再考慮。注意：如果你現有的提示詞用了這些技巧，可能會讓 GPT-4.1 過度關注它們。

常見的「翻車」場景（不只 GPT-4.1 有）：

- 過於僵化的規則： 指示模型「必須」做某事有時會有反效果。例如，你說「回應使用者前必須呼叫工具」，模型在資訊不足時可能會幻想出工具輸入或用空值呼叫。可以加上「如果你沒有足夠的資訊來呼叫工具，請向使用者詢問所需資訊」來緩解。
- 變成複讀機： 提供範例語句時，模型可能會一字不漏地照搬，聽起來很重複。記得指示模型「根據情況適當變化」。
- 話癆或格式控： 如果沒有特別指示，模型可能過於熱衷解釋自己的決策，或輸出過多不必要的格式。透過指令和範例來約束。

## 終極提示詞結構與分隔符建議

一路看下來，你可能想問，到底一個「好」的提示詞長什麼樣？這裡提供一個不錯的起始結構，你可以根據需求增刪調整：

```plaintext
# 角色與目標 (Role and Objective)
# 指令 (Instructions)
## 更詳細指令的子分類 (Sub-categories for more detailed instructions)
# 推理步驟 (Reasoning Steps)
# 輸出格式 (Output Format)
# 範例 (Examples)
## 範例 1 (Example 1)
# 上下文 (Context)
# 最終指令與逐步思考提示 (Final instructions and prompt to think step by step)
```

選對「分隔符」，事半功倍

用什麼符號來區分提示詞的不同部分也很重要。

- Markdown： 推薦首選！用 # 做標題（支援多層級），用 ` ` 或 包裹程式碼，用標準的數字或項目符號列表。簡單直觀。
- XML 標籤： 效果也不錯，GPT-4.1 對 XML 結構的理解有提升。方便精確包裹區塊、添加元數據、實現嵌套。例如： <examples> <example type= "Abbreviate" > <input> San Francisco </input> <output> - SF </output> </example> </examples>
- JSON： 結構化程度高，模型尤其在程式碼相關場景下理解很好。但可能比較冗長，需要處理字符轉義。

針對大量文件/長文本的特別建議：

- XML 在長文本測試中表現良好。 例：<doc id=1 title=”狐狸”>敏捷的棕色狐狸跳過懶狗</doc>
- Lee et al. 提出的格式 也表現不錯。 例：ID: 1 | TITLE: 狐狸 | CONTENT: 敏捷的棕色狐狸跳過懶狗
- JSON 表現相對較差。

總之，選擇分隔符的原則是：清晰、能讓模型「一眼看到」重點。例如，如果你提供的上下文裡本身就有很多 XML，那再用 XML 做分隔符效果可能就打折扣了。

一些小提醒 (Caveats)：

- 在極少數情況下，模型可能不太願意產生非常長、重複性的輸出（例如逐一分析數百個項目）。如果你的應用需要這樣，請強力指示模型完整輸出，或者考慮拆分問題、使用更簡潔的方法。
- 觀察到極少數並行工具呼叫 (parallel tool calls) 出錯的情況。建議測試一下，如果遇到問題，可以考慮將 parallel_tool_calls 參數設為 false 。

## 結語：釋放 GPT-4.1 的全部力量

GPT-4.1 無疑是個強大的工具，但要真正發揮它的潛力，關鍵在於「提示詞」。記住，它更像一個嚴格遵循食譜的廚師，而不是一個會讀心術的大師。

- 指令要清晰、具體、無歧義。
- 善用 Agentic Workflows 的三大提醒：Persistence, Tool-calling, Planning。
- 處理長文本時，注意指令擺放和上下文依賴的調整。
- 透過 Chain of Thought 引導模型「大聲思考」。
- 利用範例和結構化的提示詞來精確控制輸出。
- 最重要的是：不斷實驗、評估、迭代！

希望這份指南能幫助你更好地駕馭 GPT-4.1，創造出更驚豔的應用！
